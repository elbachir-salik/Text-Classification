{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P9pbdGrYgRl",
        "outputId": "842a9bd3-4723-4a1c-f14a-114fd7a1c35d"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J-wqekxpZlbu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import torch\n",
        "df = pd.read_csv(\"beach_review_binary.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUwuj1fMZqJt",
        "outputId": "31110d9c-7959-4883-cc51-585dd92698a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['review', 'sentiment'], dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bbedS49ZqdD",
        "outputId": "11ae52c9-ff16-4fde-8d09-5e34d0597e1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "positive    137\n",
              "negative    108\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JPLvYfHmZskD"
      },
      "outputs": [],
      "source": [
        "df['review'] = df['review'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsVwT5_XZu57",
        "outputId": "eac384ca-bf00-430e-b864-ae5faaa75efe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'transformers.models.distilbert.modeling_distilbert.DistilBertModel'>\n",
            "DistilBertModel(\n",
            "  (embeddings): Embeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (transformer): Transformer(\n",
            "    (layer): ModuleList(\n",
            "      (0): TransformerBlock(\n",
            "        (attention): MultiHeadSelfAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (ffn): FFN(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (activation): GELUActivation()\n",
            "        )\n",
            "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerBlock(\n",
            "        (attention): MultiHeadSelfAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (ffn): FFN(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (activation): GELUActivation()\n",
            "        )\n",
            "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerBlock(\n",
            "        (attention): MultiHeadSelfAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (ffn): FFN(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (activation): GELUActivation()\n",
            "        )\n",
            "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerBlock(\n",
            "        (attention): MultiHeadSelfAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (ffn): FFN(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (activation): GELUActivation()\n",
            "        )\n",
            "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerBlock(\n",
            "        (attention): MultiHeadSelfAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (ffn): FFN(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (activation): GELUActivation()\n",
            "        )\n",
            "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerBlock(\n",
            "        (attention): MultiHeadSelfAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (ffn): FFN(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (activation): GELUActivation()\n",
            "        )\n",
            "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(type(model))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8SYkey6XZwrb"
      },
      "outputs": [],
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C9lorrcKZz-E"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "inputs = [\n",
        "  tokenizer(sentence, padding=True, max_length = 512, truncation=True, return_tensors='pt')\n",
        "  for sentence in df['review']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meRWzN39Z0XL",
        "outputId": "f9c7e653-3d82-427a-e55f-cb7ebab5ed4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "features = [\n",
        "           mean_pooling(model(**input), input['attention_mask'])[0].detach().numpy()\n",
        "           for input in inputs\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au0NCF3bZ8FV",
        "outputId": "4951e971-3db1-49dd-ef70-e5879c9b6abc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OASX9FP6Z9x9"
      },
      "outputs": [],
      "source": [
        "labels = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztl8lei6aBxb",
        "outputId": "4ba562ff-3cd7-441b-8923-e6e8eb2b0073"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nKuTenjbaCSs"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import datasets\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oN4ouOQwhaDu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gjnKdMoLhnom"
      },
      "outputs": [],
      "source": [
        "abc = AdaBoostClassifier(n_estimators=50,\n",
        "                         learning_rate=1)\n",
        "# Train Adaboost Classifer\n",
        "model = abc.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLJFPUYVhrcG",
        "outputId": "ab969d8c-433f-46fa-ea9e-cab824b29caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7837837837837838\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IWrhQrxWkG31"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
        "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
        "              \"n_estimators\": [1, 2]\n",
        "             }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "owpwE7C5kPmM"
      },
      "outputs": [],
      "source": [
        "adab = AdaBoostClassifier()\n",
        "ada_p_dist={'learning_rate':[0.25,0.5,0.75,1.],\n",
        "            'n_estimators':[100,250,500,650],\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fkJlO-mVku6M"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "def hypertuning_rscv(adab, p_distr, nbr_iter,X,y):\n",
        "    rdmsearch = RandomizedSearchCV(adab, param_distributions=p_distr,\n",
        "                                  n_jobs=-1, n_iter=nbr_iter, cv=9)\n",
        "    #CV = Cross-Validation ( here using Stratified KFold CV)\n",
        "    start = time()\n",
        "    rdmsearch.fit(X,y)\n",
        "    print('hyper-tuning time : %d seconds' % (time()-start))\n",
        "    start = 0\n",
        "    ht_params = rdmsearch.best_params_\n",
        "    ht_score = rdmsearch.best_score_\n",
        "    return ht_params, ht_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idSowhBUkjCl",
        "outputId": "4c398e49-3055-4130-fd06-9571d8c49ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hyper-tuning time : 45 seconds\n",
            "{'n_estimators': 250, 'learning_rate': 0.25}\n",
            "Hyper-tuned model score :\n",
            "84.7953216374269\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "ada_parameters, ada_ht_score = hypertuning_rscv(adab, ada_p_dist, 10, X_train, y_train)\n",
        "print(ada_parameters)\n",
        "print('Hyper-tuned model score :')\n",
        "print(ada_ht_score*100)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4sEo9gW9m7aL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oUKyHy3kmau0"
      },
      "outputs": [],
      "source": [
        "crossvalidation=KFold(n_splits=10,shuffle=True,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tJfsQIxYklcl"
      },
      "outputs": [],
      "source": [
        "ada=AdaBoostClassifier()\n",
        "search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1]}\n",
        "search=GridSearchCV(estimator=ada,param_grid=search_grid,scoring='accuracy',n_jobs=1,cv=crossvalidation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EINQ3eixmlT8",
        "outputId": "9e49879c-28b2-4b44-e1ce-3b1ac6bc1cd2"
      },
      "outputs": [],
      "source": [
        "search.fit(X_train,y_train)\n",
        "search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PJFyXIzmoiU",
        "outputId": "220df476-7244-482c-c2df-536575159a80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AdaBoostClassifier(learning_rate=1, n_estimators=1000)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "ada = AdaBoostClassifier(n_estimators=1000,learning_rate=1)\n",
        "ada.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(ada,open(\"model.pkl\",\"wb\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f731cd98fa383c9beb807c28a525db8ce83ca2cad88f6953f7d402721aaf42b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
